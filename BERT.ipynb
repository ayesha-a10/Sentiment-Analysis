{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc8ef948-7a04-4f0c-b2b5-c51fa09019bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    DataCollatorWithPadding, \n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7014bb36-851d-45ba-85b6-d4b563aba15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files=r\"C:\\Users\\ASUS\\Downloads\\Datasets\\binary_class.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d40f144-5da7-45c2-952f-3f830a70f1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d08e0b79-081a-442f-8f24-3ab5e53f5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "338c9550-8a3c-4e40-ae45-f56399930d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"review\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "encoded_dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "encoded_dataset = encoded_dataset.remove_columns([\"review\"])\n",
    "\n",
    "encoded_dataset = encoded_dataset.rename_column(\"sentiment\", \"labels\")\n",
    "\n",
    "# Convert string labels to integers\n",
    "def encode_label(example):\n",
    "    example[\"labels\"] = 1 if example[\"labels\"] == \"positive\" else 0\n",
    "    return example\n",
    "\n",
    "encoded_dataset = encoded_dataset.map(encode_label)\n",
    "\n",
    "encoded_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce27549e-ecea-497b-8b62-3ebb6ea4de2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86fbd2e1-63eb-4de0-ae32-8d614e7cccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd12f2f8-8501-4630-9931-faf6200a23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveEveryHourCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.last_save_time = time.time()\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_save_time >= 3600:  # 1 hour\n",
    "            save_path = os.path.join(args.output_dir, f\"hourly_save_step_{state.global_step}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            kwargs[\"model\"].save_pretrained(save_path)\n",
    "            print(f\"\\nğŸ“Œ Model auto-saved at {save_path}\\n\")\n",
    "            self.last_save_time = current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36ef829c-b0ce-4039-90cd-fd117c6f8f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_cpu_sentiment\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,      # CPU friendly\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,      # Simulate batch_size=16\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",                   # no wandb\n",
    "    fp16=False,                         # CPU cannot use fp16\n",
    "    bf16=False,                         # no bfloat16 on CPU\n",
    "    dataloader_num_workers=0,           # CPU safe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40cb1ee6-c5a9-406f-9822-fdb39e3d7115",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_10904\\1080335483.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[SaveEveryHourCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c953751-312d-412e-8fad-56efaba3949e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4000' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4000/4000 95:53:20, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213000</td>\n",
       "      <td>0.207495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.125200</td>\n",
       "      <td>0.263135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_45\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_91\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_137\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_183\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_228\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_274\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_321\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_367\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_414\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_460\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_507\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_553\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_599\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_647\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_695\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_741\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_788\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_834\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_880\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_926\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_971\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1017\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1063\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1108\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1153\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1198\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1242\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1287\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1333\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1380\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1425\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1473\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1523\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1570\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1617\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1660\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1704\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1748\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1792\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1834\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1878\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1923\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_1967\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2001\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2045\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2089\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2133\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2177\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2221\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2265\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2309\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2354\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2399\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2444\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2488\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2531\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2574\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2618\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2661\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2704\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2747\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2790\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2832\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2873\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2913\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2953\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_2993\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3033\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3073\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3112\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3150\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3189\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3225\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3261\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3301\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3342\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3380\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3419\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3458\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3498\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3537\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3577\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3617\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3657\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3697\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3736\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3775\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3814\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3852\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3890\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3928\n",
      "\n",
      "\n",
      "ğŸ“Œ Model auto-saved at ./bert_cpu_sentiment\\hourly_save_step_3967\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4000, training_loss=0.20166178596019746, metrics={'train_runtime': 345272.1891, 'train_samples_per_second': 0.185, 'train_steps_per_second': 0.012, 'total_flos': 8419553771520000.0, 'train_loss': 0.20166178596019746, 'epoch': 2.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfa0a16c-3c26-4b3b-b759-acadbd108cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./bert_cpu_sentiment/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e5533f9-ed96-4ae4-b948-e3216762fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "829f9cfa-5891-423e-a447-db4a7e4714d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.9293\n",
      "Precision: 0.9188\n",
      "Recall   : 0.9426\n",
      "F1-Score : 0.9305\n"
     ]
    }
   ],
   "source": [
    "preds = torch.argmax(torch.tensor(predictions.predictions), dim=1).numpy()\n",
    "acc = accuracy_score(labels, preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-Score : {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
